<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.5.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-11-19T19:32:11+05:30</updated><id>http://localhost:4000/</id><title type="html">Rahul Mayuranath</title><subtitle>A blog about technology and stuff related</subtitle><entry><title type="html">Build a Fake News Classifier</title><link href="http://localhost:4000/Building-A-Fake-News-Classifier/" rel="alternate" type="text/html" title="Build a Fake News Classifier" /><published>2017-11-19T18:30:00+05:30</published><updated>2017-11-19T18:30:00+05:30</updated><id>http://localhost:4000/Building%20A%20Fake%20News%20Classifier</id><content type="html" xml:base="http://localhost:4000/Building-A-Fake-News-Classifier/">&lt;h2 id=&quot;introduction-to-the-problem&quot;&gt;Introduction to the problem&lt;/h2&gt;

&lt;p&gt;The advent of social media has enabled news to spread to a global audience in a matter of seconds, bypassing the usual verification procedures employed by news outlets in the past. As such, the past year had seen a phenomenal increase in spurious articles and features making their way to the social media space. This, coupled with the intentional attempts by spammers and foreign powers to spread misinformation among the voting populace was highlighted during the US Presidential Elections of 2016. Voters across the country were duped by fabricated stories and satirical news misinterpreted as factual, compromising the electoral process.&lt;/p&gt;

&lt;p&gt;Given the size of the problem at hand, an automated classification system would undermine the effects of spurious or irrelevant news in media feeds. This system tries to help users make more informed decisions on which news stories to believe and which should be taken with a grain of salt. To do so, our system will be trained on a dataset consisting of headlines and articles which have a mix of true and fake headlines. Some of these fake headlines and articles have been derived from satirical sources, while the rest from websites known to push false information. With the intention of making this system quick and efficient, the model is also trained with the headlines only, which is always easier to scrape. Also, in a real-world use case application, the headline could conceivably be derived from the URL of the website itself. We also looked at the variation in the accuracy of our models when using just the headlines versus just the body of the article.&lt;/p&gt;

&lt;p&gt;Our ultimate objective for this project is to effectively and automatically label news articles as fake or real. The models assign labels to news articles based on the textual contents of the headlines and text bodies separately. The dataset for the problem consists of around 30,000 entries, conforming to a format of Article title, Text body and associated label. The dataset was assembled by sampling recent fake and news articles datasets from across the internet.&lt;/p&gt;

&lt;p&gt;We assumed that accurate results could be inferred from just textual analysis. Although some previous work suggests that semantic disambiguation is just as important, we believed that fictitious or ‘fake’ articles would have a clear repetitive use of specific vocabulary. It was reasonably expected that spurious news generated in the backlash of the US Presidential Election would have higher references towards either of the final presidential candidates, and their alleged controversies.&lt;/p&gt;

&lt;h3 id=&quot;approach&quot;&gt;APPROACH&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/iRyVIam.png&quot; alt=&quot;alt text&quot; title=&quot;Approach used&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Corporations like Facebook and Twitter have faced severe backlash for being unable to filter the content that streams on their respective platforms. The community took up the challenge to build reliable models to combat this issue over the past year. This inspired us to try our hand at solving this problem. 
We built our dataset by sampling from multiple datasets online.
This was necessary since a single data source lacked the variety that we needed. Our dataset turned out to be skewed since we had more fake articles. To fix this, we found other datasets of authentic news in a number of categories and built a final dataset containing 30,000 articles.&lt;/p&gt;

&lt;h3 id=&quot;dimensionality-reduction&quot;&gt;Dimensionality Reduction:&lt;/h3&gt;
&lt;p&gt;We eyeballed the data and decided we only needed the headline and the news article. We removed features such as source URL because this would overly simplify the task at hand. Removed fields such as likes, comments and shares because these are not indicative of authentic news. Satirical and fictitious articles have been trending on social media and as such these metrics cannot be used to distinguish between real and fake.
For initial analysis, we built a word cloud of the fake and real corpora. The word cloud debunked our initial analysis that spurious articles would have more references to the US Presidential Election candidates but these references appeared equally in both the word clouds.
Next, we vectorized our dataset using unigram TF-IDF. This is a weighted measure of how often a particular phrase occurs in a document relative to how often the phrase occurs across all documents in a corpus. This helps us to focus on the words in the articles and headlines that convey meaning. We use SKLearn to calculate the TFIDF for each word within each document and build a sparse matrix of the resulting features. We did not experiment with different methods or thresholds for selecting the terms included in the vocabulary, or with different lengths of n-grams, but this may be an area to explore in future work.​
Next logical step is to split our data into test and training sets. We employed k-fold cross validation for the same. In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once. [ 7 ]
Next, a number of classifier models were built on this dataset, namely SVM, Logistic Regression, Random Forest, Naive Bayes Classifier and an LSTM Neural Network. 
Results were interpreted and our models were pickled so that we don't have to train it again each time.&lt;/p&gt;

&lt;h2 id=&quot;experimentation-and-results&quot;&gt;EXPERIMENTATION AND RESULTS&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/18acSIH.png&quot; alt=&quot;alt text&quot; title=&quot;Fake News word cloud&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/pFFCq02.png&quot; alt=&quot;alt text&quot; title=&quot;Real News word cloud&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Our preliminary investigation involved building separate word clouds for articles labelled as ‘real’’ and ‘fake’. The ‘nltk’ library in python has a corpus of stop words in English. This was used to clean our data by removing the stop words before the clouds were generated.
The purpose of these word clouds was to test our assumption that spurious articles generated in the wake of the US Presidential elections(2016) would have more references to the candidates or controversy they were embroiled in. The word clouds on the articles could not validate our assumption since these words occurred equally in both authentic and fictitious articles. What we did notice however, is that in the word clouds of headlines of fake news, all the words were related to politics, and in the real news it had references to other topics, such as Entertainment (Christian Bale is referenced).&lt;/p&gt;

&lt;p&gt;The next step involved splitting the complete dataset of around 30,000 articles  into a train-test split of 80:20, and performing TF-IDF separately on the news headlines and news bodies to generate two separate feature vectors. Stop words were removed while performing TF-IDF. The weights for each feature were scaled logarithmically, and only those features whose frequencies fell within the specified range were chosen.&lt;/p&gt;

&lt;p&gt;The feature vectors obtained from TF-IDF were used to build the Naive Bayes, SVM, Logistic Regression, Random Forests and LSTM models.&lt;/p&gt;

&lt;p&gt;The Naive Bayes classifier attempts to label articles into either category by utilizing a Bayesian probabilistic model that assumes independence among the features. The conditional probability of the document belonging to either label is calculated and a label is assigned.
Naive Bayes model was chosen as a baseline for reference, owing to its simplicity. For the title, we got an accuracy of 68.52\%, while the body resulted in a 90.23\% accuracy score. Already, the difference in using the body of the article is evident. It also suggests that titles of articles are made to be misleading, and that there are no obvious patterns that differentiate fake or real.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/PPqhIWq.png&quot; alt=&quot;alt text&quot; title=&quot;Naive Bayes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Support Vector Machines attempt to fit a hyperplane, or line as such, through an n-dimensional vector space to maximally separate points into regions. Each region has a label associated with it. The SVM generated very high accuracies (with high F1 scores, indicating the model was good). The accuracy obtained by using the body was 95.87\% compared to that by using the title is  73.4\%.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/uDLP1GD.png&quot; alt=&quot;alt text&quot; title=&quot;SVM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Logistic Regression attempts to predict a dependant dichotomous variable from a set of independent variables. This works for our model as we are trying to apply a label, ‘fake’ or ‘real’, to our news articles given that the label depends on the content of news headline and text body. It resulted in an accuracy of 94.6\% by using the body.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/OAk2qyv.png&quot; alt=&quot;alt text&quot; title=&quot;Logistic Regression&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set[ Quoted from wikipedia ]. With an accuracy of 96.42\% by using the headlines and 74.01\%, Random Forests was also a well performing classifier and gave the highest accuracy for the text body.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/8Shs4Wh.png&amp;quot;Random Forests&amp;quot;&quot; alt=&quot;alt text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Long short-term memory (LSTM) block or network is a simple recurrent neural network which can be used as a building component or block (of hidden layers) for an eventually bigger recurrent neural network.The expression long short-term refers to the fact that LSTM is a model for the short-term memory which can last for a long period of time. There are different types of LSTMs, which differ among them in the components or connections that they have.[ Quoted from Wikipedia ] Our results from the Recurrent Neural Network were quite surprising. It was unable to outperform the Random Forests model when classifying documents by text body giving an accuracy of 93.95\%. However it performed miles ahead of the other models when classifying documents by looking at just the news headlines, with an accuracy of 91.37\%.&lt;/p&gt;

&lt;p&gt;Traditional machine learning models have a chance of overfitting their results to the training data. In order to avoid this, we performed a K-folds cross validation for each of these models on each feature vector. The K-Folds Cross validation procedure divides the dataset into k ‘folds’ or chunks. It iteratively selects one of these k chunks of the dataset and uses the other (k-1) folds as the training set. This implies that every ‘fold’ or ‘chunk’ in the dataset will appear in the training data (k-1) times with each chunk being used as the testing data. For better visualization, our cross validation procedure was tested by incrementally increasing the size of the dataset, and iteratively applying the k-folds procedure. This was helpful in understanding how the metrics of our models changed as the number of data points increased.&lt;/p&gt;

&lt;p&gt;One of the goals of our experiment was to determine whether spurious articles could be recognized from their headlines alone. It was observed that all our traditional machine learning models couldn’t accurately separate the fake and real articles as well as having low recall. This poor performance can probably be attributed to a lack of  dissimilarity between the feature vectors of fake and real articles. Not to mention, we preprocessed our data beforehand, removing stop words and the like, which reduced the number of features for these models.&lt;/p&gt;

&lt;p&gt;Surprisingly enough our RNN was able to accurately label articles by looking at just the headlines alone. We were unable to determine exactly why our LSTM performed so well on headlines and this appears to be an interesting area for further study.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;CONCLUSION&lt;/h2&gt;

&lt;p&gt;Random Forests achieved the highest accuracy of ~96\% for the text body while the LSTM Neural Network performed the best for the article headlines with an accuracy of ~92\%. The difference in using the body of the article is clear, with the difference in the accuracy of each classifier being at least 15 percentage points when using traditional classification systems.  This leads us to two conclusions. One is that article headlines are made to be more misleading and that traditional classification systems are poor when trying to classify textual data with just one sentence, i.e., a very small set of words.&lt;/p&gt;

&lt;p&gt;In the future, the classification system could be expanded to implement a stance detection system, as required by the Fake News Challenge [ 10 ]. Stance Detection here refers to the ability of the system to decide whether the text of the article agrees with the headline, disagrees with the headline, discusses the topic of the headline, but does not take a position if the headline and body are unrelated.&lt;/p&gt;

&lt;h2 id=&quot;limitations&quot;&gt;LIMITATIONS&lt;/h2&gt;

&lt;p&gt;There are a few limitations to our analysis that prevents broader generalizability.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;While TF-IDF performs well, we are possibly overfitting to the data from the news cycle that we chose.&lt;/li&gt;
  &lt;li&gt;With limited verified sources of fake news, we cannot claim that this approach would generalize to unseen sources.&lt;/li&gt;
  &lt;li&gt;With heavy reliance on term frequencies, we cannot be confident that this approach would generalize across news cycles.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I collaborated with my team mates Ravi Shreyas Anupindi and Hiranmaya Gundu on the above analysis.&lt;br /&gt;
The github repo of the entire implentation is &lt;a href=&quot;https://github.com/rahul-1996/fake_news_classifier&quot;&gt;here&lt;/a&gt;. Thanks for reading!&lt;/p&gt;</content><author><name>rahulmayuranath</name></author><category term="blog" /><category term="Fake News Classifier" /><category term="Machine Learning" /><category term="Python" /><category term="Neural Networks" /><summary type="html">Introduction to the problem</summary></entry><entry><title type="html">Suffix Trees</title><link href="http://localhost:4000/suffix-trees/" rel="alternate" type="text/html" title="Suffix Trees" /><published>2017-10-20T22:48:00+05:30</published><updated>2017-10-20T22:48:00+05:30</updated><id>http://localhost:4000/suffix-trees</id><content type="html" xml:base="http://localhost:4000/suffix-trees/">&lt;p&gt;Suffix tree is a compressed trie of all the suffixes of a given string.
Edges that direct to a node having single child are combined together to form a single edge and their edge labels are concatenated. Hence, each internal node has at least two children. The space complexity of the suffix tree is O(n), if optimisations are made.&lt;/p&gt;

&lt;h3 id=&quot;construction-of-the-suffix-tree&quot;&gt;Construction of the suffix tree:&lt;/h3&gt;

&lt;p&gt;The following resource was used a reference while building the suffix tree:
&lt;a href=&quot;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/suffix_trees.pdf&quot;&gt;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/suffix_trees.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Each node in the suffix tree has :&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Label on path from this edge to the next node&lt;/li&gt;
  &lt;li&gt;A dictionary of outgoing edges; Characters are mapped to nodes.&lt;/li&gt;
  &lt;li&gt;Leaves; All leaf nodes of the corresponding node.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To insert into the suffix tree, we first insert the longest suffix(i.e the entire string) into the suffix tree. The root node will map the first character with an edge label comprising the entire string.
Now, we keep inserting smaller suffixes until we exhaust the suffixes.
We either fall off in the middle of an edge or fall off at a node.
The latter case is easy to handle since we just have to add an edge hanging off the current node.
To handle the former case, we create a new middle node from where we “fell off” the tree.
The original child becomes the node node’s child and its label is curtailed from where the mismatch occurs. The new child is also added to the current node.&lt;/p&gt;

&lt;p&gt;The above algorithm builds a suffix tree for a single string. 
A Generalized Suffix Tree(GST) is constructed for all the string in the document. Once the all the strings are added to the above tree in a similar way, we proceed to insert the leaf nodes. 
We need to keep track of which position the string is in the text; To achieve this, every leaf node consists the position number of the that string in the document. 
Now the substring problem is just reduced to returning text[index] for all indexes present in the leaves.&lt;/p&gt;

&lt;p&gt;We should also preprocess the text so that we can segregate tale titles and their corresponding tale. 
The problems can be answered now that we have the suffix tree built and the text has been preprocessed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;list-all-the-occurrences-of-a-query-string-in-the-set-of-documents-&quot;&gt;List all the occurrences of a query-string in the set of documents. &lt;br /&gt;&lt;/h4&gt;
    &lt;p&gt;We iterate over each of the tales individually and search for the query string. If we end at a leaf node, we return all the indexes contained in the leaf string. If we end at an internal node, we DFS over all the nodes rooted at the current node and return the indexes from all the leaves. This will return all occurrences of the string. Once we get all the indexes, we also print a few words surrounding the word. Getting the corresponding document is trivial since we are iterating for each document separately. This takes O(n+k) for each tale, where k is the number of the matches.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; For tree rooted at the given node, we recursively visit all children nodes 
           until we exhaust the tree. &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;
    
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getLeaves&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; We DFS and get all nodes rooted below the node. We iterate over their
            leaves and get the corresponding positions and return a list of positions&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;followPath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;visited&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;list-only-the-first-occurrence-of-a-given-query-string-in-every-document-if-the-query-string-is-not-present-find-the-first-occurrence-of-the-longest-substring-of-the-query-string-&quot;&gt;List only the first occurrence of a given query-string in every document. If the query-string is not present, find the first occurrence of the longest substring of the query-string. &lt;br /&gt;&lt;/h4&gt;
    &lt;p&gt;This question is similar to the one above with minor modifications. 
We do the same as above, but only return the smallest index for each tale that are returned by the leaves. This will trivially be the first occurrence, since it has the smallest index. If the string is not present in the text, we slice the string and keep trying for smaller substrings, until an exact match is found.&lt;br /&gt; &lt;br /&gt;
This will take O(n+k)z time for each tale, where z is number of substrings.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h4 id=&quot;for-a-given-query-string-query-of-words-list-the-documents-ranked-by-the-relevance&quot;&gt;For a given query-string (query of words), list the documents ranked by the relevance.&lt;/h4&gt;
    &lt;p&gt;We maintain a list of ranks for each of the documents.
The ranking criteria is as follows:
For a query string entered, we split it into its corresponding words.
If an exact match is found for a word, we increment the rank of that document by 100. If a match is not found, we try for smaller substrings until we exhaust the string. For each smaller match, the rank reduces. (Eg: Matching banana fetches 100, matching banan fetches 50).
This is done for every word in the query string.
At last, we sort the ranks by their index and return the rank of the documents.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;occasion when the shepherd laid hold of him&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Words is a list consisting of all the words of the query string. &lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# List of ranks to rank the document. &lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot; We first look for an exact match of the word. If it is not present, 
    we look for smaller substrings. We assign a score of 100/z for a match 
    that is found, where z is the slice index. Trivially, exact matches will have 
    a higher total score. Finally we sort the rank list by index(Not by magnitude of rank)
    and return the list of documents &quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;312&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;queryWord&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;312&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SuffixTree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lenFinal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;finalWords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lenFinal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;found&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finalWords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lenFinal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insertLeaves&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finalWords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;found&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLeaves&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queryWord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
                &lt;span class=&quot;c&quot;&gt;# We increment total rank of the document and choose the first occurance.  &lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;found&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;leaves&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;


&lt;span class=&quot;c&quot;&gt;#Sorting ranks by their index&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Printing documents &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Rank &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; : &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ranks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The github repo of the entire implentation is &lt;a href=&quot;https://github.com/rahul-1996/Suffix-Tree&quot;&gt;here&lt;/a&gt;. Thanks for reading!&lt;/p&gt;</content><author><name>rahulmayuranath</name></author><category term="blog" /><category term="Suffix trees" /><category term="Python" /><summary type="html">Suffix tree is a compressed trie of all the suffixes of a given string. Edges that direct to a node having single child are combined together to form a single edge and their edge labels are concatenated. Hence, each internal node has at least two children. The space complexity of the suffix tree is O(n), if optimisations are made.</summary></entry></feed>